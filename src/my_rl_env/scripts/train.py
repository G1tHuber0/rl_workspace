#!/usr/bin/env python3
import torch
import argparse
import os

torch.set_num_threads(2)
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import sys
import gymnasium as gym
import time
import numpy as np
from stable_baselines3 import DQN, PPO, A2C,TD3
from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor
from stable_baselines3.common.utils import set_random_seed

# å°è¯•å¯¼å…¥ç¯å¢ƒï¼Œå…¼å®¹ä¸åŒçš„ç›®å½•ç»“æ„
try:
    from turtlebot_env import TurtleBotEnv
except ImportError:
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•æŠŠå½“å‰ç›®å½•åŠ å…¥è·¯å¾„
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from turtlebot_env import TurtleBotEnv

# ==========================================
# 1. é…ç½®åŒºåŸŸ (ä¸æ‚¨ä¹‹å‰çš„é…ç½®ä¿æŒä¸€è‡´)
# ==========================================

ALGOS = {
    "dqn": DQN,
    "ppo": PPO,
    "a2c": A2C,
}

HYPERPARAMS = {
    "dqn": {
        "policy": "MlpPolicy",
        "learning_rate": 7e-4, 
        "buffer_size": 100_000, # å¹¶è¡Œåæ•°æ®é‡å¤§ï¼ŒåŠ å¤§ç»éªŒæ± 
        "learning_starts": 10_000, 
        "batch_size": 128,      
        "exploration_fraction": 0.4, 
        "exploration_final_eps": 0.05,
        "gamma": 0.99,            
        "target_update_interval": 1000,
        "gradient_steps" : 1,
    },
    "ppo": {
        "policy": "MlpPolicy",
        "learning_rate": 3e-4,
        "n_steps": 2048,
        "batch_size": 256,
        "n_epochs": 10,
        "ent_coef": 0.01,
        "gae_lambda": 0.95,
        "clip_range": 0.2,
    },
    "a2c": {
        "policy": "MlpPolicy",
        "learning_rate": 7e-4,
        "n_steps": 20,
        "ent_coef": 0.01,
    }
}

def make_env(rank, seed=0):
    """
    ç”¨äºåˆ›å»ºç¯å¢ƒçš„è¾…åŠ©å‡½æ•°ï¼ŒSubprocVecEnv éœ€è¦è¿™ä¸ªå‡½æ•°
    :param rank: ç¯å¢ƒçš„ç´¢å¼• (0, 1, 2, ...) -> å¯¹åº” worker_id
    :param seed: éšæœºç§å­
    """
    def _init():
        # ä¼ å…¥ worker_idï¼Œè§¦å‘ turtlebot_env.py ä¸­çš„å¹¶è¡Œé€»è¾‘ (ä¿®æ”¹ç¯å¢ƒå˜é‡)
        env = TurtleBotEnv(worker_id=rank)
        # è®¾ç½®ä¸åŒçš„éšæœºç§å­ï¼Œä¿è¯æ¯ä¸ªç¯å¢ƒçš„éšæœºæ€§ä¸åŒ
        env.reset(seed=seed + rank) 
        return env
    return _init

def get_args():
    parser = argparse.ArgumentParser(description="TurtleBot3 å¹¶è¡Œè®­ç»ƒè„šæœ¬")
    parser.add_argument("--algo", type=str, default="ppo", choices=ALGOS.keys())
    parser.add_argument("--steps", type=int, default=500000, help="è®­ç»ƒæ€»æ­¥æ•°")
    parser.add_argument("--n_envs", type=int, default=6, help="å¹¶è¡Œç¯å¢ƒæ•°é‡ (éœ€ä¸ launch_parallel.py ä¸€è‡´)")
    parser.add_argument("--save_name", type=str, default="turtlebot_parallel")
    parser.add_argument("--load", type=str, default=None)
    return parser.parse_args()

def main():
    args = get_args()
    
    # è·¯å¾„è®¾ç½®
    script_dir = os.path.dirname(os.path.abspath(__file__))
    log_dir = os.path.join(script_dir, "../logs")
    model_dir = os.path.join(script_dir, "../models")
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(model_dir, exist_ok=True)

    print(f"ğŸš€ [Train] ä»»åŠ¡å¯åŠ¨: ç®—æ³•={args.algo.upper()}, è¿›ç¨‹æ•°={args.n_envs}, æ€»æ­¥æ•°={args.steps}")

    # ==========================================
    # 2. åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ (æ ¸å¿ƒä¿®æ”¹)
    # ==========================================
    # SubprocVecEnv ä¼šåœ¨åå°åˆ›å»º n_envs ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹è¿è¡Œä¸€ä¸ª make_env è¿”å›çš„ç¯å¢ƒ
    # è¿™é‡Œçš„ i å¯¹åº” worker_id (0, 1, 2...)
    env = SubprocVecEnv([make_env(i) for i in range(args.n_envs)])
    
    # VecMonitor ç”¨äºè®°å½•æ¯ä¸ª episode çš„å¥–åŠ±å’Œé•¿åº¦ï¼Œæ–¹ä¾¿ Tensorboard æ˜¾ç¤º
    # å®ƒä¼šè‡ªåŠ¨ç»Ÿè®¡æ‰€æœ‰å¹¶è¡Œç¯å¢ƒçš„æ•°æ®
    env = VecMonitor(env, filename=os.path.join(log_dir, "monitor.csv"))

    # 3. å®ä¾‹åŒ–/åŠ è½½ æ¨¡å‹
    if args.algo not in ALGOS: raise ValueError(f"Unknown algo: {args.algo}")
    AlgorithmClass = ALGOS[args.algo]
    
    if args.load:
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {args.load}")
        # æ³¨æ„: load æ—¶éœ€è¦ä¼ å…¥ envï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨é€‚åº”å‘é‡åŒ–ç¯å¢ƒ
        model = AlgorithmClass.load(args.load, env=env, tensorboard_log=log_dir)
    else:
        print(f"âœ¨ åˆ›å»ºæ–°æ¨¡å‹ ({args.algo})")
        algo_params = HYPERPARAMS.get(args.algo, {})
        
        final_kwargs = {
            "env": env,
            "verbose": 1,
            "tensorboard_log": log_dir,
            "device": "auto",
            **algo_params
        }
        model = AlgorithmClass(**final_kwargs)

    # 4. å¼€å§‹è®­ç»ƒ
    start_time = time.time()
    try:
        print("â³ å¼€å§‹è®­ç»ƒ...")
        # total_timesteps æ˜¯æ‰€æœ‰ç¯å¢ƒåŠ èµ·æ¥çš„æ€»æ­¥æ•°
        model.learn(total_timesteps=args.steps, progress_bar=True,log_interval=1)
        
        # 5. ä¿å­˜æ¨¡å‹
        save_path = os.path.join(model_dir, f"{args.algo}_{args.save_name}")
        model.save(save_path)
        print(f"âœ… è®­ç»ƒå®Œæˆ! è€—æ—¶: {(time.time()-start_time)/60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}.zip")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ‰‹åŠ¨ä¸­æ–­ï¼Œæ­£åœ¨ç´§æ€¥ä¿å­˜...")
        save_path = os.path.join(model_dir, f"{args.algo}_{args.save_name}_interrupted")
        model.save(save_path)
        print(f"ğŸ’¾ ç´§æ€¥å¤‡ä»½å·²ä¿å­˜: {save_path}.zip")
        
    finally:
        # å…³é—­æ‰€æœ‰å¹¶è¡Œç¯å¢ƒè¿›ç¨‹
        env.close()
        print("[Train] æ‰€æœ‰ç¯å¢ƒå·²å…³é—­")

if __name__ == "__main__":
    main()